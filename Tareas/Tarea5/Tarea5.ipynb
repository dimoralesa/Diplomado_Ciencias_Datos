{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOTo4kPV0+XnC9N2c/wiQ59",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimoralesa/Diplomado_Ciencias_Datos/blob/main/Tareas/Tarea5/Tarea5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMnKmHAbqnkW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from math import sqrt\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from scipy import stats\n",
        "from statsmodels.stats.diagnostic import normal_ad"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"GOOG\"\n",
        "now = datetime.now()\n",
        "data = yf.Ticker(data).history(start=(now-relativedelta(years=10)).strftime(\"%Y-%m-%d\"),\n",
        "                                            end=now.strftime(\"%Y-%m-%d\"))[['Open', 'High', 'Low', 'Close', 'Volume']]"
      ],
      "metadata": {
        "id": "QNOXmrsPsPO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'\\n Forma de los datos: {data.shape}\\n')\n",
        "data"
      ],
      "metadata": {
        "id": "Hc_HvXF-sPRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google = data[['Close']]\n",
        "google"
      ],
      "metadata": {
        "id": "K4bgQs4OuVtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tamaño de pasos a futuro\n",
        "future_target = 20\n",
        "\n",
        "# tamaño secuencias de entrada\n",
        "past_history = 55\n",
        "\n",
        "def multipaso_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size,  single_step=False):\n",
        "    ''' dataset: conjunto de datos para las secuencias de entrada\n",
        "        target:  conjunto de datos para las secuencias de salida\n",
        "        start_index: índice inicial de donde empezar a tomar los datos\n",
        "        end_index: índice final para tomar los datos. None para tomarlos todos\n",
        "        history_size: tamaño de la ventana para crear las secuencias\n",
        "        target_size: dentro de cuántas observaciones futuras desea pronosticar\n",
        "        single_step: Predecir solamente un valor futuro (=True),\n",
        "                     o predecir todos los valores hasta target_size(=False)\n",
        "    '''\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    start_index = start_index + history_size\n",
        "    if end_index is None:\n",
        "        end_index = len(dataset) - target_size\n",
        "\n",
        "    for i in range(start_index, end_index):\n",
        "        indices = range(i-history_size, i)\n",
        "        data.append(dataset[indices])\n",
        "\n",
        "        if single_step:\n",
        "            labels.append(target[i+target_size])\n",
        "        else:\n",
        "            labels.append(target[i:i+target_size])\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "def create_and_train_model(X_train, y_train, X_test, y_test, units):\n",
        "    input_shape = (X_train.shape[1], 1)\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "    x = Dropout(0.0, name= 'Dropout_01')(inputs)\n",
        "    x = LSTM(units=units, name='LSTM_layer')(x)\n",
        "    x = LSTM(units=units, return_sequences=True,name='LSTM_layer')(inputs)\n",
        "    x = LSTM(units=units//2, name='LSTM_layer_2')(x)\n",
        "    outputs = Dense(future_target)(x)\n",
        "\n",
        "    # model\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='series_LSTM_model')\n",
        "    model.compile(loss='mean_squared_error', optimizer=Adam(0.001))\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=40,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        verbose=1,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    prediction = model.predict(X_test)\n",
        "    pred = 0\n",
        "    y_train_p = X_test[pred,:]\n",
        "    y_test_p = y_test[pred,:]\n",
        "    y_pred_p = prediction[pred,:]\n",
        "\n",
        "    y_train_p = scaler.inverse_transform(y_train_p.reshape(-1, 1))\n",
        "    y_test_p = scaler.inverse_transform(y_test_p.reshape(-1, 1))\n",
        "    y_pred_p = scaler.inverse_transform(y_pred_p.reshape(-1, 1))\n",
        "\n",
        "    return history, y_train_p, y_test_p, y_pred_p\n",
        "\n",
        "def plot_residuals(residuals):\n",
        "    sw_result = stats.shapiro(residuals)\n",
        "    ad_result = normal_ad(np.array(residuals), axis=0)\n",
        "    dag_result = stats.normaltest(residuals, axis=0, nan_policy='propagate')\n",
        "\n",
        "    plt.figure(figsize=(15,7))\n",
        "    res = stats.probplot(residuals, plot=plt)\n",
        "    ax = plt.gca()\n",
        "    ax.annotate(\"SW p-val: {:.4f}\".format(sw_result[1]), xy=(0.05,0.9), xycoords='axes fraction', fontsize=15,\n",
        "                bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n",
        "    ax.annotate(\"AD p-val: {:.4f}\".format(ad_result[1]), xy=(0.05,0.8), xycoords='axes fraction', fontsize=15,\n",
        "                bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n",
        "    ax.annotate(\"DAG p-val: {:.4f}\".format(dag_result[1]), xy=(0.05,0.7), xycoords='axes fraction', fontsize=15,\n",
        "                bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\", pad=0.6))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confidence_intervals(residuals, y_train, y_test, y_pred):\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    y_train = [arr[0] for arr in y_train.tolist()]\n",
        "    y_test = [arr[0] for arr in y_test.tolist()]\n",
        "    y_pred = [arr[0] for arr in y_pred.tolist()]\n",
        "\n",
        "    RMSFE = np.sqrt(sum([x**2 for x in residuals]) / len(residuals))\n",
        "    band_size = 1.96*RMSFE\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15,7))\n",
        "    ax.plot(list(range(len(y_train))), y_train, color='g', label='History')\n",
        "    ax.plot(list(range(len(y_train), len(y_train) + len(y_test))), y_test, color='#fc7d0b', label='True')\n",
        "    ax.scatter(list(range(len(y_train), len(y_train) + len(y_test))), y_pred)\n",
        "    ax.fill_between(list(range(len(y_train), len(y_train) + len(y_test))), (y_test-band_size), (y_test+band_size), color='b', alpha=.1)\n",
        "    ax.set_title(\"Predictions w/ 95% Confidence\")\n",
        "    ax.set_xlabel('Timestep')\n",
        "    ax.set_ylabel('Price')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "S1vrQXB3tCTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_data = len(google)\n",
        "len_train = int(len_data*0.8)\n",
        "len_test = len_data- len_train\n",
        "\n",
        "dataset = google.values\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = np.squeeze(np.array(scaler.fit_transform(dataset)),axis=1)\n",
        "\n",
        "TRAIN_SPLIT = int(len_data*0.8)\n",
        "\n",
        "X_train, y_train = multipaso_data(dataset, dataset, 0,\n",
        "                                                 TRAIN_SPLIT, past_history,\n",
        "                                                 future_target)\n",
        "X_test, y_test = multipaso_data(dataset, dataset, TRAIN_SPLIT,\n",
        "                                                 None, past_history,\n",
        "                                                 future_target)\n",
        "\n",
        "print(TRAIN_SPLIT)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "iRhU8WQotCWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_google, y_train_google, y_test_google, y_pred_google = create_and_train_model(X_train, y_train, X_test, y_test, 50)"
      ],
      "metadata": {
        "id": "lVW8NtvttCaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_google.history['loss'], label='train')\n",
        "plt.plot(history_google.history['val_loss'], label='test')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "86hkVcWltCmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals_google = sorted([(x - y)[0] for x, y in zip(y_pred_google, y_test_google)])\n",
        "plot_confidence_intervals(residuals_google, y_train_google, y_test_google, y_pred_google)"
      ],
      "metadata": {
        "id": "V9XKm-pmzNUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}